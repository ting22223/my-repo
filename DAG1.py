from airflow import DAGfrom airflow.operators.bash import BashOperatorfrom airflow.operators.trigger_dagrun import TriggerDagRunOperatorfrom datetime import datetime, timedelta# 定义默认参数default_args = {    'owner': 'airflow',    'start_date': datetime(2024, 7, 17),}# 定义 DAG1DAG1 = DAG(    'DAG1',    default_args=default_args,    schedule=None,  # 设置为 None，手动触发)# 定义任务流程 p1 >> p2 >> p3 >> p5p1 = BashOperator(    task_id='p1',    bash_command='echo "Executing p1"',    dag=DAG1)p2 = BashOperator(    task_id='p2',    bash_command='echo "Executing p2"',    dag=DAG1)p3 = BashOperator(    task_id='p3',    bash_command='exit 1',  # 模拟失败    dag=DAG1)p4 = BashOperator(    task_id='p4',    bash_command='echo "Executing p4"',    dag=DAG1)# 设置任务依赖关系p1 >> p2 >> p3>>p4# 在 DAG1 中使用 TriggerDagRunOperator 触发 DAG2trigger_dag2 = TriggerDagRunOperator(    task_id='trigger_dag2',    trigger_dag_id='DAG2',    dag=DAG1,    execution_date="{{ execution_date }}",    wait_for_completion=True,  # 等待 DAG2 执行完成    trigger_rule='all_success',  # 仅在上游任务成功时触发 DAG2)# 设置触发器，当 p2 成功后触发 DAG2p2 >> trigger_dag2# 定义 DAG2DAG2 = DAG(    'DAG2',    default_args=default_args,    schedule=None,  # 设置为 None，手动触发)# 定义支流任务 p4 >> p5p3_1 = BashOperator(    task_id='p3_1',    bash_command='echo "Executing p3_1"',    dag=DAG2)p4_1 = BashOperator(    task_id='p4',    bash_command='echo "Executing p4_1"',    dag=DAG2)# 设置 DAG2 的任务依赖关系p3_1>>p4_1